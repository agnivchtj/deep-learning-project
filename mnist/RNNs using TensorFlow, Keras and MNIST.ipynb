{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks using TensorFlow, Keras and MNIST data\n",
    "\n",
    "Recurrent Neural Networks retain the importance of sequential data as they are feeded through a regular model; this is done by taking the output of the activation function and including it as input back into the cell of same layer. This can be problematic for several reasons: how is the new incoming data weighed? How is recurring data handled? What about as we continue down the layer? \n",
    "\n",
    "In order to tackle these problems, we can make use of Long Short-Term Memory (LSTM) cells which use functions to determine what to remove, add and output from the new incoming data so that data that is fed to next layer remains undominated by that initial signal. To start, we can look at applying a RNN to MNIST data; this dataset consists of 28x28 images of handwritten digits, from 0 to 9. Our goal is to build a RNN that can accurately recognize /classify the images upon receiving as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "\n",
    "## We can normalize the pixel values in the training / test set to be between 0-1\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our sequential RNN model with `LSTM` cells in the hidden layer, as opposed to `Conv`, and we use the `return_sequences` flag to indicate that we want to pass on the output to the recurrent layer (which we want to do here). We can set up the parameters for our model compilation, with a learning rate of `1e-3` and decay of `1e-5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agniv\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.7276 - accuracy: 0.7516\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1942 - accuracy: 0.9470\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.1282 - accuracy: 0.9656\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0984 - accuracy: 0.9743\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 61s 32ms/step - loss: 0.0821 - accuracy: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b40ddd4bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = x_train.shape[1:], activation = tf.nn.relu, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, activation = tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation = tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 1e-3, decay = 1e-5), \n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we train our model through multiple iterations, we can see that our loss metric decreases substantially and accuracy improves from 75.2% to 97.8%. We will also simulate this on our test data to ensure our model didn't simply memorize every detail in the training set (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0584 - accuracy: 0.9822\n",
      "The value of loss is:  0.05836750566959381\n",
      "The accuracy of the model is:  0.982200026512146\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"The value of loss is: \", val_loss)\n",
    "print(\"The accuracy of the model is: \", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we get similar values for loss and accuracy (98.2%) when simulating our model on the test (out-of-sample) data, so this would indicate that our model has learned to classify MNIST in general. We can now output the list of predictions in a Pandas dataframe and export it to CSV for record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step\n",
      "[[6.5262143e-11 1.2424092e-06 8.5909314e-06 ... 9.9997437e-01\n",
      "  9.0901239e-08 1.1122986e-05]\n",
      " [3.8835662e-12 4.8277088e-10 1.0000000e+00 ... 7.0377723e-12\n",
      "  2.3169053e-12 1.8195709e-18]\n",
      " [9.7758555e-21 1.0000000e+00 9.4659697e-12 ... 4.3876992e-16\n",
      "  2.9993605e-17 3.3658389e-21]\n",
      " ...\n",
      " [5.5423536e-19 4.4065568e-14 4.8842215e-15 ... 2.3761690e-08\n",
      "  5.1430464e-15 8.6626535e-08]\n",
      " [6.1678902e-09 8.5714663e-10 1.8843656e-08 ... 1.6188957e-10\n",
      "  1.8174236e-05 4.2993761e-06]\n",
      " [1.4056303e-06 3.8656391e-12 5.7264202e-08 ... 8.8433887e-16\n",
      "  1.4163020e-08 6.1598453e-13]]\n",
      "\n",
      "\n",
      "      Predictions\n",
      "0               7\n",
      "1               2\n",
      "2               1\n",
      "3               0\n",
      "4               4\n",
      "...           ...\n",
      "9995            2\n",
      "9996            3\n",
      "9997            4\n",
      "9998            5\n",
      "9999            6\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "print(preds)\n",
    "print('\\n')\n",
    "\n",
    "predictions = pd.DataFrame([np.argmax(preds[i]) for i in range(0, 10000)])\n",
    "predictions.columns = ['Predictions']\n",
    "predictions.to_csv('predictions_rnn_mnist.txt', index=False, header=False)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
